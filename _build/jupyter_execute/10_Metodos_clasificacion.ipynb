{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25fc9a6c",
   "metadata": {},
   "source": [
    "# Segundo resumen sobre modelos de clasificación supervisada\n",
    "\n",
    "En este capítulo, revisaremos los modelos de clasificación que no se vieron en el primer resumen. Veremos los siguientes modelos:\n",
    "\n",
    "- Support Vector Machines (SVM)\n",
    "- Naive Bayes \n",
    "- Gradient Boosting\n",
    "- Redes Neuronales Artificiales\n",
    "\n",
    "Como en el anterior capítulo, no solo cubriremos la teoría y la intuición detrás de Random Forest y otros métodos de clasificación supervisada, sino que también proporcionaremos ejemplos prácticos y ejercicios en Python. Utilizaremos librerías populares como scikit-learn, que ofrece implementaciones eficientes y fáciles de usar de una variedad de algoritmos de aprendizaje automático.\n",
    "\n",
    "Cada uno de estos modelos tiene sus propias fortalezas y situaciones en las que es más adecuado. A lo largo de este capítulo, exploraremos en detalle cómo cada uno funciona, cómo se implementan en Python utilizando scikit-learn u otras bibliotecas relevantes, y en qué situaciones podrían ser la mejor opción para tus proyectos de clasificación supervisada.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4bc673",
   "metadata": {},
   "source": [
    "Recordemos la estructura abstracta para entrenar modelos en scikit-learn:\n",
    "\n",
    "```{note} Sintaxis General para Modelos de Clasificación en Scikit-learn\n",
    "\n",
    "En scikit-learn, la implementación de modelos de clasificación supervisada sigue un patrón consistente, lo que facilita la experimentación con diferentes algoritmos. Este patrón se puede describir en unos pocos pasos generales aplicables a cualquier modelo de clasificación. Aquí te muestro cómo se ve esta sintaxis de manera abstracta:\n",
    "\n",
    "### Pasos Generales\n",
    "\n",
    "1. **Importar el Modelo:** Primero, se importa la clase correspondiente al modelo que deseas utilizar desde scikit-learn.\n",
    "\n",
    "    ```python\n",
    "    from sklearn.[modulo] import [Modelo]\n",
    "    ```\n",
    "\n",
    "2. **Instanciar el Modelo:** Creas una instancia del modelo, donde puedes especificar varios hiperparámetros según tus necesidades. Si no estás seguro, puedes empezar con los valores predeterminados.\n",
    "\n",
    "    ```python\n",
    "    modelo = [Modelo](hiperparametro1=valor1, hiperparametro2=valor2, ...)\n",
    "    ```\n",
    "\n",
    "3. **Entrenar el Modelo:** Utilizas el método `.fit()` para entrenar el modelo con tus datos de entrenamiento. Esto ajustará los parámetros del modelo para minimizar el error de predicción.\n",
    "\n",
    "    ```python\n",
    "    modelo.fit(X_train, y_train)\n",
    "    ```\n",
    "\n",
    "4. **Hacer Predicciones:** Una vez entrenado el modelo, puedes usar el método `.predict()` para hacer predicciones sobre nuevos datos.\n",
    "\n",
    "    ```python\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    ```\n",
    "\n",
    "**Ejemplo Genérico**\n",
    "\n",
    "Aquí tienes un ejemplo genérico que muestra cómo aplicar estos pasos:\n",
    "\n",
    "```python\n",
    "# Paso 1: Importar el modelo\n",
    "from sklearn.[modulo] import [Modelo]\n",
    "\n",
    "# Paso 2: Instanciar el modelo con los hiperparámetros deseados\n",
    "modelo = [Modelo](hiperparametro1=valor1, hiperparametro2=valor2, ...)\n",
    "\n",
    "# Paso 3: Entrenar el modelo\n",
    "modelo.fit(X_train, y_train)\n",
    "\n",
    "# Paso 4: Hacer predicciones\n",
    "y_pred = modelo.predict(X_test)\n",
    "```\n",
    "Es importante recordar que `[modulo]`, `[Modelo]`, `hiperparametro1`, `valor1`, etc., son marcadores de posición. Deben reemplazarce con los nombres específicos y valores relevantes para el modelo que estás utilizando. Esta estructura te permite adaptar fácilmente el código para diferentes modelos de clasificación supervisada en scikit-learn.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce346d4",
   "metadata": {},
   "source": [
    "## Cómo Funciona Support Vector Machines (SVM)\n",
    "\n",
    "Support Vector Machines (SVM) representa uno de los algoritmos más robustos y precisos dentro del aprendizaje supervisado, especialmente utilizado para problemas de clasificación. Este algoritmo se basa en la idea de encontrar el mejor hiperplano que separa las distintas clases en el espacio de características.\n",
    "\n",
    "```{note}\n",
    "El hiperplano en el contexto de SVM es conceptualmente similar a una línea de división en 2D, pero extendido a espacios de mayor dimensión. Su objetivo es maximizar el margen entre las clases de datos, siendo este margen la distancia mínima entre el hiperplano y los puntos más cercanos de las clases (vectores de soporte).\n",
    "```\n",
    "\n",
    "### Principios Fundamentales de SVM\n",
    "\n",
    "1. **Identificación del Mejor Hiperplano:** SVM comienza el proceso de clasificación buscando el hiperplano que ofrece la mayor separación (margen) entre las diferentes clases. En un espacio de dos dimensiones, este hiperplano puede visualizarse como una línea.\n",
    "\n",
    "2. **Maximización del Margen:** El margen se define como la distancia entre el hiperplano y los vectores de soporte más cercanos. Los vectores de soporte son aquellos puntos de datos que están más cerca del hiperplano. SVM optimiza este margen para mejorar la capacidad del modelo para generalizar bien a nuevos datos.\n",
    "\n",
    "3. **Uso del Truco del Kernel:** En situaciones donde los datos no son linealmente separables, SVM utiliza técnicas de kernel para transformar el espacio de entrada en un espacio de mayor dimensión donde los datos pueden ser separados linealmente. Esto permite a SVM manejar eficazmente relaciones complejas y no lineales entre las características.\n",
    "\n",
    "```{note}\n",
    "A través del truco del kernel, SVM es capaz de realizar clasificaciones complejas y no lineales utilizando espacios de características transformados, sin necesidad de calcular explícitamente las dimensiones adicionales.\n",
    "```\n",
    "\n",
    "### Visualización del Algoritmo SVM\n",
    "\n",
    "Imagina que estás en un campo abierto donde se encuentran dispersos dos tipos de flores. Tu tarea es trazar una línea recta (en este caso, el hiperplano) que separe lo mejor posible estos dos tipos de flores. El enfoque de SVM no solo se centra en trazar esta línea sino en posicionarla de tal manera que la distancia (margen) entre la línea y las flores más cercanas a ella (de ambos tipos) sea la máxima posible. Esto es equivalente a maximizar la tolerancia al error en la clasificación de futuras muestras de flores.\n",
    "\n",
    "```{image} images/SVM.png\n",
    ":alt: Support Vector Machines\n",
    ":align: center\n",
    "```\n",
    "\n",
    "```{image} images/SVM_2.png\n",
    ":alt: Support Vector Machines Algorithm\n",
    ":align: center\n",
    "```\n",
    "\n",
    "SVM se destaca por su efectividad en espacios de alta dimensión y su capacidad para manejar fronteras de decisión complejas y no lineales, gracias al uso de funciones kernel. Este enfoque, centrado en la maximización del margen y en la importancia crítica de los vectores de soporte, permite que SVM sea altamente efectivo y preciso en la clasificación, incluso en situaciones donde la relación entre las características no es inmediatamente evidente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9abec1d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ejemplo sencillo \n",
    "\n",
    "## Dataset de prueba [Iris]\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target'].astype(int)],\n",
    "                        columns= iris['feature_names'] + ['target'])\n",
    "\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22c44c12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df['target'].astype(int).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31ace5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (90, 4)\n",
      "X test shape: (60, 4)\n"
     ]
    }
   ],
   "source": [
    "## Dividir el dataset en entrenamiento y prueba\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_df[iris['feature_names']], iris_df['target'], test_size=0.4, stratify=iris_df['target'].astype(int), random_state=0)\n",
    "\n",
    "print('X train shape:', X_train.shape)\n",
    "print('X test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597cd64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        20\n",
      "         1.0       1.00      1.00      1.00        20\n",
      "         2.0       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        60\n",
      "   macro avg       1.00      1.00      1.00        60\n",
      "weighted avg       1.00      1.00      1.00        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Ahora clasificación con SVM\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(kernel='linear', C=1.0, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "## Predicción\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "## Evaluación\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6f760f",
   "metadata": {},
   "source": [
    "### Hipérparámetros Importantes de SVM\n",
    "\n",
    "SVM tiene varios hiperparámetros que pueden ajustarse para mejorar el rendimiento del modelo. `scikit-learn` proporciona valores predeterminados razonables para estos hiperparámetros, pero es importante comprender cómo afectan al modelo. Algunos de los hiperparámetros más importantes de SVM son:\n",
    "\n",
    "- **c:** Parámetro de regularización que controla la compensación entre la maximización del margen y la minimización de la clasificación incorrecta. Un valor más alto de `C` dará como resultado un margen más estrecho pero una clasificación más precisa.\n",
    "\n",
    "- **kernel:** Especifica el tipo de kernel a utilizar en la transformación de los datos. Los kernels comunes incluyen `linear`, `poly`, `rbf` (radial basis function), y `sigmoid`.\n",
    "\n",
    "- **gamma:** Coeficiente del kernel para los kernels `rbf`, `poly`, y `sigmoid`. Un valor más alto de `gamma` dará como resultado un ajuste más preciso a los datos de entrenamiento, pero puede llevar a un sobreajuste."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858bb855",
   "metadata": {},
   "source": [
    "\n",
    "### Naive Bayes\n",
    "\n",
    "**Naive Bayes** es un conjunto de algoritmos de clasificación supervisada basados en el teorema de Bayes con la \"naive\" suposición de independencia entre las características. A pesar de su simplicidad, Naive Bayes puede superar a modelos de clasificación más complejos.\n",
    "\n",
    "- **Ventajas**: Simple, rápido y efectivo en conjuntos de datos de gran dimensión.\n",
    "- **Desventajas**: La suposición de independencia entre características no siempre se cumple en datos reales.\n",
    "\n",
    "**Ejemplo práctico**: Clasificación de especies de Iris basada en medidas de sus características.\n",
    "\n",
    "**Más información**: [Scikit-learn Naive Bayes](https://scikit-learn.org/stable/modules/naive_bayes.html)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16a688ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ejemplo sencillo \n",
    "\n",
    "## Dataset de prueba [Iris]\n",
    "\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target'].astype(int)],\n",
    "                        columns= iris['feature_names'] + ['target'])\n",
    "\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cb9239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " iris_df['target'].astype(int).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99a2b90a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (90, 4)\n",
      "X test shape: (60, 4)\n"
     ]
    }
   ],
   "source": [
    "## Dividir el dataset en entrenamiento y prueba\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_df[iris['feature_names']], iris_df['target'], test_size=0.4, stratify=iris_df['target'].astype(int), random_state=0)\n",
    "\n",
    "print('X train shape:', X_train.shape)\n",
    "print('X test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "785239de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        20\n",
      "         1.0       0.90      0.95      0.93        20\n",
      "         2.0       0.95      0.90      0.92        20\n",
      "\n",
      "    accuracy                           0.95        60\n",
      "   macro avg       0.95      0.95      0.95        60\n",
      "weighted avg       0.95      0.95      0.95        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Ahora clasificación con Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "## Predicción\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "## Evaluación\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c22943f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ejemplo de Implementación con Naive Bayes en scikit-learn\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear y entrenar el modelo Naive Bayes\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones y evaluar el modelo\n",
    "y_pred = gnb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}